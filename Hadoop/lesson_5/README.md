# Урок 5. Форматы хранения

## Задачи

1. Развернуть [кластер](https://github.com/big-data-europe/docker-hive) через [Docker](https://www.docker.com/products/docker-desktop) (или выполнить ДЗ на учебном кластере, удалив файлы потом)
2. Загрузить в наш развернутый hdfs самый большой файл из [датасета](https://www.kaggle.com/fivethirtyeight/uber-pickups-in-new-york-city) и сделать external table (образец с лекции тут )
3. Далее создать таблицы с разными форматами как в local_hive.sql и попробовать пописать различные запросы, засечь и сравнить время.
4. Повторить эксперимент с паркетом и orc добавив 2 различных сжатия (GZIP/SNAPPY) и сравнить получившийся размер файлов с изначальным, а так же время выполнения запросов.

## Решение

Были получены выборки с помощью запросов:

1 запрос: select count(*) from data
2 запрос: select count(locationID) from data;
3 запрос: select count(distinct Dispatching_base_num) from data;

Проверялась скорость выполнения запросов в зависимости от способа хранения данных. Для этого делалось три запроса. И при каджом запросе записывалось время его выполнения (в секундах):

-- stored as TEXTFILE

--- | 1 попытка | 2 попытка | 3 попытка
--- | --- | --- | ---
1 | 7.587 | 4.453 | 4.368
2 | 6.388 | 6.307 | 6.331
3 | 9.404 | 6.519 | 6.338

-- stored as PARQUET.compression=UNCOMPRESSED 

--- | 1 попытка | 2 попытка | 3 попытка
--- | --- | --- | ---
1 | 0.122 | 0.097 | 0.083
2 | 6.307 | 6.283 | 6.484
3 | 6.316 | 6.29 | 6.344

-- stored as PARQUET.compression=GZIP 

--- | 1 попытка | 2 попытка | 3 попытка
--- | --- | --- | ---
1 | 0.772 | 0.167 | 0.22
2 | 1.904 | 1.495 | 1.388
3 | 1.353 | 1.391 | 1.353

-- stored as PARQUET.compression=SNAPPY 

--- | 1 попытка | 2 попытка | 3 попытка
--- | --- | --- | ---
1 | 0.11 | 0.106 | 0.094
2 | 1.904 | 1.495 | 1.388
3 | 1.323 | 1.411 | 1.327

-- stored as SequenceFile

--- | 1 попытка | 2 попытка | 3 попытка
--- | --- | --- | ---
1 | 0.132 | 0.101 | 0.077
2 | 23.334 | 23.339 | 22.359
3 | 23.379 | 23.398 | 23.344

-- stored as PARQUET

--- | 1 попытка | 2 попытка | 3 попытка
--- | --- | --- | ---
1 | 0.112 | 0.109 | 0.111 
2 | 4.342 | 4.344 | 4.322
3 | 4.312 | 4.301 | 4.304

-- stored as ORC UNCOMPRESSED

--- | 1 попытка | 2 попытка | 3 попытка
--- | --- | --- | ---
1 | 0.102 | 0.101 | 0.068
2 | 4.3 | 4.302 | 4.303
3 | 4.31 | 4.306 | 4.308

-- stored as ORC ZLIB

--- | 1 попытка | 2 попытка | 3 попытка
--- | --- | --- | ---
1 | 0.125 | 0.107 | 0.118
2 | 5.369 | 4.42 | 4.398
3 | 4.398 | 5.36 | 5.409

-- stored as AVRO 

--- | 1 попытка | 2 попытка | 3 попытка
--- | --- | --- | ---
1 | 0.074 | 0.101 | 0.097
2 | 29.327 | 28.441 | 28.392
3 | 30.31 | 30.347 | 30.424

Для построения графиков использовалось только последнее полученное значение, когда все метаданные и кеш уже созданы.

--- | **запрос 1**
ORC UNCOMPRESSED | 0,068
SequenceFile | 0,077
PARQUET UNCOMPRESSED | 0,083
PARQUET SNAPPY  | 0,094
AVRO | 0,097
ORC ZLIB | 0,118
PARQUET GZIP  | 0,22
TEXTFILE | 4,368

--- | **запрос 2**
PARQUET GZIP  | 1,388
PARQUET SNAPPY  | 1,388
ORC UNCOMPRESSED | 4,303
ORC ZLIB | 4,398
TEXTFILE | 6,331
PARQUET UNCOMPRESSED | 6,484
SequenceFile | 22,359
AVRO | 28,392

--- | **запрос 3**
PARQUET SNAPPY  | 1,327
PARQUET GZIP  | 1,353
ORC UNCOMPRESSED | 4,308
ORC ZLIB | 5,409
TEXTFILE | 6,338
PARQUET UNCOMPRESSED | 6,344
SequenceFile | 23,344
AVRO | 30,424


Из результатов можно сделать вывод, что одним из наиболее универсальных методов хранения для текущего набора данных является "PARQUET SNAPPY". Он занял 4-2-1 позицию по скорости обработки запросов. При этом на всех запросах время не превышало 1.4 секунды.
