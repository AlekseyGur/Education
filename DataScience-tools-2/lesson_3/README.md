# Урок 3. Построение модели классификации

## Задание

1. Для чего и в каких случаях полезны различные варианты усреднения для метрик качества классификации: micro, macro, weighted?
2. В чём разница между моделями xgboost, lightgbm и catboost или какие их основные особенности?

## Ответы

### Задача 1

Macro - это средняя оценка метрики, в которой не учитывается вес каждого класса.
Используется для оценки качества классификатора на данных, в которых есть
классы небольшого размера и верное предсказание этих классов критично.

Weighted - это средняя оценка метрики с учетом веса каждого класса.
Итоговая оценка метрики качества взвешивается на размер каждого класса. Используется
при наличии дисбаланса классов в данных. Чем меньше класс, тем больше у него вес.
Используется когда качество работы классификатора на небольших классах не является критичным.

Micro - это средняя оценка метрики качества, в которой для каждого класса суммируются
составляющие метрики (TP, FP, ...). Используется при необходимости
оценики максимального качества работы классификатора. При этом качество предсказаний
второстепенных классов не критично.

### Задача 2

В XGBoost применяется "pre-sorted algorithm & Histogram-based algorithm".
В LightGBM использует более современный "Gradient-based One-Side Sampling" алгоритм.

LightGBM и Catboost сами обрабатывают категориальные переменные. При использовании
XGBoost категориальные переменные нужно обрабатывать вручную. Catboost способен
обрабатывать категориальные параметры в виде текста, а LightGBM тольчко через "One Hot Encoding".



