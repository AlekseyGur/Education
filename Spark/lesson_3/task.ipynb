{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2hfVwCGAwt9",
        "outputId": "adca65c2-6e11-47bf-a1b0-258fcd55ed2d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.3.0)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3Q9g_UyNxS6"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        "    .master(\"local[2]\")\\\n",
        "    .appName(\"Lesson_5\")\\\n",
        "    .config(\"spark.executor.instances\",2)\\\n",
        "    .config(\"spark.executor.memory\",'2g')\\\n",
        "    .config(\"spark.executor.cores\",1)\\\n",
        "    .getOrCreate()\n",
        "    \n",
        "sc = spark.sparkContext"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Оконные функции"
      ],
      "metadata": {
        "id": "dnXLtjUr_FkX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оконная функция - функция, которая работает с выделенным набором строк (окном, партицией) и выполняет вычисление для этого набора строк в отдельном столбце. \n",
        "\n",
        "Партиции (окна из набора строк) - это набор строк, указанный для оконной функции по одному из столбцов или группе столбцов таблицы. Партиции для каждой оконной функции в запросе могут быть разделены по различным колонкам таблицы."
      ],
      "metadata": {
        "id": "JGioDDCQ_V_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Предположим, что есть таблицы:\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "data =[\n",
        "    (\"Banana\",1000,\"USA\"), (\"Carrots\",1500,\"USA\"), (\"Beans\",1600,\"USA\"),\\\n",
        "    (\"Orange\",2000,\"USA\"), (\"Orange\",2000,\"USA\"), (\"Banana\",400,\"China\"),\\\n",
        "    (\"Carrots\",1200,\"China\"), (\"Beans\",1500,\"China\"), (\"Orange\",4000,\"China\"),\\\n",
        "    (\"Banana\",2000,\"Canada\"), (\"Carrots\",2000,\"Canada\"), (\"Beans\",2000,\"Mexico\")\n",
        "    ]\n",
        "columns = [\"Product\",\"Amount\", \"Country\"]\n",
        "\n",
        "df = spark.createDataFrame(data=data, schema=columns)\n",
        "df.printSchema()\n",
        "df.show(truncate=False) # truncate - обрезать ли длинные строки"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6tdUDN5_Ee0",
        "outputId": "2c1c5da3-57eb-457f-f7b5-4f88069daf76"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Product: string (nullable = true)\n",
            " |-- Amount: long (nullable = true)\n",
            " |-- Country: string (nullable = true)\n",
            "\n",
            "+-------+------+-------+\n",
            "|Product|Amount|Country|\n",
            "+-------+------+-------+\n",
            "|Banana |1000  |USA    |\n",
            "|Carrots|1500  |USA    |\n",
            "|Beans  |1600  |USA    |\n",
            "|Orange |2000  |USA    |\n",
            "|Orange |2000  |USA    |\n",
            "|Banana |400   |China  |\n",
            "|Carrots|1200  |China  |\n",
            "|Beans  |1500  |China  |\n",
            "|Orange |4000  |China  |\n",
            "|Banana |2000  |Canada |\n",
            "|Carrots|2000  |Canada |\n",
            "|Beans  |2000  |Mexico |\n",
            "+-------+------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# в sql оконная функция записывается следующим образом\n",
        "df.registerTempTable('df')\n",
        "\n",
        "spark.sql('''\n",
        "select *, \n",
        "row_number() over( partition by Country order by Amount ) as rn from df\n",
        "''').show()"
      ],
      "metadata": {
        "id": "jhq8wrA8BNia",
        "outputId": "a3c51467-1d40-4f7a-dee4-e6e25e4ccc45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+-------+---+\n",
            "|Product|Amount|Country| rn|\n",
            "+-------+------+-------+---+\n",
            "| Banana|  2000| Canada|  1|\n",
            "|Carrots|  2000| Canada|  2|\n",
            "| Banana|   400|  China|  1|\n",
            "|Carrots|  1200|  China|  2|\n",
            "|  Beans|  1500|  China|  3|\n",
            "| Orange|  4000|  China|  4|\n",
            "|  Beans|  2000| Mexico|  1|\n",
            "| Banana|  1000|    USA|  1|\n",
            "|Carrots|  1500|    USA|  2|\n",
            "|  Beans|  1600|    USA|  3|\n",
            "| Orange|  2000|    USA|  4|\n",
            "| Orange|  2000|    USA|  5|\n",
            "+-------+------+-------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# в спарке следующим образом\n",
        "from pyspark.sql import Window\n",
        "\n",
        "\n",
        "windSpec = Window()\\\n",
        "    .partitionBy('Country')\\\n",
        "    .orderBy('Amount')\n",
        "    # .rowsBetween(Window.unboundedPreceding, Window.currentRow - 1)\n",
        "\n",
        "df.withColumn('rn', F.row_number().over(windSpec)).show()"
      ],
      "metadata": {
        "id": "9grWEK6CBbBK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ff8c1e9-f11c-4fcd-f9ae-435384a98af6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+-------+---+\n",
            "|Product|Amount|Country| rn|\n",
            "+-------+------+-------+---+\n",
            "| Banana|  2000| Canada|  1|\n",
            "|Carrots|  2000| Canada|  2|\n",
            "| Banana|   400|  China|  1|\n",
            "|Carrots|  1200|  China|  2|\n",
            "|  Beans|  1500|  China|  3|\n",
            "| Orange|  4000|  China|  4|\n",
            "|  Beans|  2000| Mexico|  1|\n",
            "| Banana|  1000|    USA|  1|\n",
            "|Carrots|  1500|    USA|  2|\n",
            "|  Beans|  1600|    USA|  3|\n",
            "| Orange|  2000|    USA|  4|\n",
            "| Orange|  2000|    USA|  5|\n",
            "+-------+------+-------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVGNGR7pN1KC"
      },
      "source": [
        "# Самостоятельная работа к уроку\n",
        "На уроке мы попробовали оконные и пользовательские функции. Теперь закрепим полученные знания."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agigNChqOHnK"
      },
      "source": [
        "## Данные: [google drive: raw_sales.csv](https://drive.google.com/file/d/1G2N7Mnt4-Tqz4JdJxutGDMbJiOr32kZp/view?usp=sharing)\n",
        "\n",
        " Каждая строчка это продажа жилья, которая состоит из следующих полей (думаю описание не требуется):\n",
        "*   date of sale\n",
        "*   price\n",
        "*   property type\n",
        "*   number of bedrooms\n",
        "*   4digit postcode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://drive.google.com/uc?export=download&id=1xbtFBPz50OBoyYFVGd-B03pCTJdCax07' -O raw_sales.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-36e65zdEEh",
        "outputId": "bd7b9f91-2a98-4104-9068-a2737c573802"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-03 11:53:10--  https://drive.google.com/uc?export=download&id=1xbtFBPz50OBoyYFVGd-B03pCTJdCax07\n",
            "Resolving drive.google.com (drive.google.com)... 142.251.45.110, 2607:f8b0:4004:83f::200e\n",
            "Connecting to drive.google.com (drive.google.com)|142.251.45.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0c-5k-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ttqsi7hbco695j2i3ftlm4d08hmdfp6o/1664797950000/04099736791713398091/*/1xbtFBPz50OBoyYFVGd-B03pCTJdCax07?e=download&uuid=3f501c4e-4936-467d-a01f-9ed0e2c2d63f [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-10-03 11:53:11--  https://doc-0c-5k-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ttqsi7hbco695j2i3ftlm4d08hmdfp6o/1664797950000/04099736791713398091/*/1xbtFBPz50OBoyYFVGd-B03pCTJdCax07?e=download&uuid=3f501c4e-4936-467d-a01f-9ed0e2c2d63f\n",
            "Resolving doc-0c-5k-docs.googleusercontent.com (doc-0c-5k-docs.googleusercontent.com)... 172.253.115.132, 2607:f8b0:4004:c06::84\n",
            "Connecting to doc-0c-5k-docs.googleusercontent.com (doc-0c-5k-docs.googleusercontent.com)|172.253.115.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1505497 (1.4M) [text/csv]\n",
            "Saving to: ‘raw_sales.csv’\n",
            "\n",
            "raw_sales.csv       100%[===================>]   1.44M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2022-10-03 11:53:11 (142 MB/s) - ‘raw_sales.csv’ saved [1505497/1505497]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('raw_sales.csv', header=True, inferSchema=True)\n",
        "df.printSchema()\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpWic7isdH6R",
        "outputId": "f73b88b9-4dde-4d4e-a082-3361a2860978"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- datesold: timestamp (nullable = true)\n",
            " |-- postcode: integer (nullable = true)\n",
            " |-- price: integer (nullable = true)\n",
            " |-- propertyType: string (nullable = true)\n",
            " |-- bedrooms: integer (nullable = true)\n",
            "\n",
            "+-------------------+--------+-------+------------+--------+\n",
            "|datesold           |postcode|price  |propertyType|bedrooms|\n",
            "+-------------------+--------+-------+------------+--------+\n",
            "|2007-02-07 00:00:00|2607    |525000 |house       |4       |\n",
            "|2007-02-27 00:00:00|2906    |290000 |house       |3       |\n",
            "|2007-03-07 00:00:00|2905    |328000 |house       |3       |\n",
            "|2007-03-09 00:00:00|2905    |380000 |house       |4       |\n",
            "|2007-03-21 00:00:00|2906    |310000 |house       |3       |\n",
            "|2007-04-04 00:00:00|2905    |465000 |house       |4       |\n",
            "|2007-04-24 00:00:00|2607    |399000 |house       |3       |\n",
            "|2007-04-30 00:00:00|2606    |1530000|house       |4       |\n",
            "|2007-05-24 00:00:00|2902    |359000 |house       |3       |\n",
            "|2007-05-25 00:00:00|2906    |320000 |house       |3       |\n",
            "|2007-06-26 00:00:00|2902    |385000 |house       |3       |\n",
            "|2007-06-27 00:00:00|2906    |305000 |house       |3       |\n",
            "|2007-06-27 00:00:00|2612    |850000 |house       |4       |\n",
            "|2007-06-28 00:00:00|2904    |765000 |house       |4       |\n",
            "|2007-06-30 00:00:00|2615    |517000 |house       |4       |\n",
            "|2007-07-02 00:00:00|2914    |800000 |house       |5       |\n",
            "|2007-07-03 00:00:00|2906    |336000 |house       |3       |\n",
            "|2007-07-06 00:00:00|2615    |535000 |house       |5       |\n",
            "|2007-07-07 00:00:00|2602    |900000 |house       |4       |\n",
            "|2007-07-08 00:00:00|2600    |327000 |house       |1       |\n",
            "+-------------------+--------+-------+------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xisyFowtQgx-"
      },
      "source": [
        "## Задание 1\n",
        "Добавьте к таблице следующие поля:\n",
        "*  Средняя стомость 10 проданных домов до текущего в том же районе (4digit postcode)\n",
        "*  Средняя стомость 10 проданных домов после текущего в том же районе (4digit postcode)\n",
        "*  Стоимость последнего проданного дома до текущего\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Window\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "# Средняя стомость 10 проданных домов до текущего в том же районе (в SQL запросе)\n",
        "df.registerTempTable('df_task_1_1')\n",
        "\n",
        "spark.sql('''\n",
        "select *, \n",
        "AVG(price) OVER(PARTITION BY postcode ORDER BY datesold ROWS BETWEEN 9 PRECEDING AND CURRENT ROW) AS avg_10_prev\n",
        "FROM df_task_1_1\n",
        "''').show(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fGJJreDczDK",
        "outputId": "e7aca758-3528-4bb5-86e3-b316cda50d09"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
            "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------+-------+------------+--------+-----------------+\n",
            "|           datesold|postcode|  price|propertyType|bedrooms|      avg_10_prev|\n",
            "+-------------------+--------+-------+------------+--------+-----------------+\n",
            "|2007-07-08 00:00:00|    2600| 327000|       house|       1|         327000.0|\n",
            "|2007-08-16 00:00:00|    2600| 790000|       house|       4|         558500.0|\n",
            "|2007-12-05 00:00:00|    2600| 825000|       house|       3|647333.3333333334|\n",
            "|2008-01-21 00:00:00|    2600| 315000|        unit|       1|         564250.0|\n",
            "|2008-04-24 00:00:00|    2600| 292500|       house|       1|         509900.0|\n",
            "|2008-05-30 00:00:00|    2600| 329000|        unit|       2|         479750.0|\n",
            "|2008-06-19 00:00:00|    2600| 765000|       house|       5|         520500.0|\n",
            "|2008-07-29 00:00:00|    2600| 927000|       house|       4|         571312.5|\n",
            "|2008-09-02 00:00:00|    2600|1380000|       house|       5|661166.6666666666|\n",
            "|2008-09-08 00:00:00|    2600| 740000|       house|       3|         669050.0|\n",
            "|2008-09-17 00:00:00|    2600| 720000|       house|       3|         708350.0|\n",
            "|2008-09-22 00:00:00|    2600| 690000|       house|       4|         698350.0|\n",
            "|2008-11-18 00:00:00|    2600| 635000|       house|       3|         679350.0|\n",
            "|2008-11-18 00:00:00|    2600| 950000|       house|       3|         742850.0|\n",
            "|2008-11-21 00:00:00|    2600| 730000|       house|       3|         786600.0|\n",
            "+-------------------+--------+-------+------------+--------+-----------------+\n",
            "only showing top 15 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Средняя стомость 10 проданных домов до текущего в том же районе (в pyspark)\n",
        "w = Window().partitionBy('postcode')\\\n",
        "            .orderBy('datesold')\\\n",
        "            .rowsBetween(Window.currentRow - 9, Window.currentRow)\n",
        "\n",
        "df.withColumn('avg_10_prev', F.mean('price').over(w)).show(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj9YQdXTXN8I",
        "outputId": "7cbcb6f8-9e48-4aea-ade3-e731d182f848"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------+-------+------------+--------+-----------------+\n",
            "|           datesold|postcode|  price|propertyType|bedrooms|      avg_10_prev|\n",
            "+-------------------+--------+-------+------------+--------+-----------------+\n",
            "|2007-07-08 00:00:00|    2600| 327000|       house|       1|         327000.0|\n",
            "|2007-08-16 00:00:00|    2600| 790000|       house|       4|         558500.0|\n",
            "|2007-12-05 00:00:00|    2600| 825000|       house|       3|647333.3333333334|\n",
            "|2008-01-21 00:00:00|    2600| 315000|        unit|       1|         564250.0|\n",
            "|2008-04-24 00:00:00|    2600| 292500|       house|       1|         509900.0|\n",
            "|2008-05-30 00:00:00|    2600| 329000|        unit|       2|         479750.0|\n",
            "|2008-06-19 00:00:00|    2600| 765000|       house|       5|         520500.0|\n",
            "|2008-07-29 00:00:00|    2600| 927000|       house|       4|         571312.5|\n",
            "|2008-09-02 00:00:00|    2600|1380000|       house|       5|661166.6666666666|\n",
            "|2008-09-08 00:00:00|    2600| 740000|       house|       3|         669050.0|\n",
            "|2008-09-17 00:00:00|    2600| 720000|       house|       3|         708350.0|\n",
            "|2008-09-22 00:00:00|    2600| 690000|       house|       4|         698350.0|\n",
            "|2008-11-18 00:00:00|    2600| 635000|       house|       3|         679350.0|\n",
            "|2008-11-18 00:00:00|    2600| 950000|       house|       3|         742850.0|\n",
            "|2008-11-21 00:00:00|    2600| 730000|       house|       3|         786600.0|\n",
            "+-------------------+--------+-------+------------+--------+-----------------+\n",
            "only showing top 15 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Средняя стомость 10 проданных домов после текущего в том же районе (в SQL)\n",
        "df.registerTempTable('df_task_1_2')\n",
        "\n",
        "spark.sql('''\n",
        "select *, \n",
        "AVG(price) OVER(PARTITION BY postcode ORDER BY datesold ROWS BETWEEN CURRENT ROW AND 9 FOLLOWING) AS avg_10_next\n",
        "FROM df_task_1_2\n",
        "''').show(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQRTGpl7UiFS",
        "outputId": "30d0af49-e7c7-4138-9969-3d5e5cc67a54"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
            "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------+-------+------------+--------+-----------+\n",
            "|           datesold|postcode|  price|propertyType|bedrooms|avg_10_next|\n",
            "+-------------------+--------+-------+------------+--------+-----------+\n",
            "|2007-07-08 00:00:00|    2600| 327000|       house|       1|   669050.0|\n",
            "|2007-08-16 00:00:00|    2600| 790000|       house|       4|   708350.0|\n",
            "|2007-12-05 00:00:00|    2600| 825000|       house|       3|   698350.0|\n",
            "|2008-01-21 00:00:00|    2600| 315000|        unit|       1|   679350.0|\n",
            "|2008-04-24 00:00:00|    2600| 292500|       house|       1|   742850.0|\n",
            "|2008-05-30 00:00:00|    2600| 329000|        unit|       2|   786600.0|\n",
            "|2008-06-19 00:00:00|    2600| 765000|       house|       5|   839200.0|\n",
            "|2008-07-29 00:00:00|    2600| 927000|       house|       4|   868450.0|\n",
            "|2008-09-02 00:00:00|    2600|1380000|       house|       5|   805750.0|\n",
            "|2008-09-08 00:00:00|    2600| 740000|       house|       3|   715250.0|\n",
            "|2008-09-17 00:00:00|    2600| 720000|       house|       3|   756250.0|\n",
            "|2008-09-22 00:00:00|    2600| 690000|       house|       4|   741750.0|\n",
            "|2008-11-18 00:00:00|    2600| 635000|       house|       3|   730550.0|\n",
            "|2008-11-18 00:00:00|    2600| 950000|       house|       3|   755050.0|\n",
            "|2008-11-21 00:00:00|    2600| 730000|       house|       3|   701050.0|\n",
            "+-------------------+--------+-------+------------+--------+-----------+\n",
            "only showing top 15 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Средняя стомость 10 проданных домов после текущего в том же районе (в pyspark)\n",
        "\n",
        "w = Window().partitionBy('postcode')\\\n",
        "            .orderBy('datesold')\\\n",
        "            .rowsBetween(Window.currentRow, Window.currentRow + 9)\n",
        "\n",
        "df.withColumn('avg_10_next', F.mean('price').over(w)).show(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3w_NAMZ4ABn",
        "outputId": "768aed91-9c15-47e0-c4db-b0ead95171d1"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------+-------+------------+--------+-----------+\n",
            "|           datesold|postcode|  price|propertyType|bedrooms|avg_10_next|\n",
            "+-------------------+--------+-------+------------+--------+-----------+\n",
            "|2007-07-08 00:00:00|    2600| 327000|       house|       1|   669050.0|\n",
            "|2007-08-16 00:00:00|    2600| 790000|       house|       4|   708350.0|\n",
            "|2007-12-05 00:00:00|    2600| 825000|       house|       3|   698350.0|\n",
            "|2008-01-21 00:00:00|    2600| 315000|        unit|       1|   679350.0|\n",
            "|2008-04-24 00:00:00|    2600| 292500|       house|       1|   742850.0|\n",
            "|2008-05-30 00:00:00|    2600| 329000|        unit|       2|   786600.0|\n",
            "|2008-06-19 00:00:00|    2600| 765000|       house|       5|   839200.0|\n",
            "|2008-07-29 00:00:00|    2600| 927000|       house|       4|   868450.0|\n",
            "|2008-09-02 00:00:00|    2600|1380000|       house|       5|   805750.0|\n",
            "|2008-09-08 00:00:00|    2600| 740000|       house|       3|   715250.0|\n",
            "|2008-09-17 00:00:00|    2600| 720000|       house|       3|   756250.0|\n",
            "|2008-09-22 00:00:00|    2600| 690000|       house|       4|   741750.0|\n",
            "|2008-11-18 00:00:00|    2600| 635000|       house|       3|   730550.0|\n",
            "|2008-11-18 00:00:00|    2600| 950000|       house|       3|   755050.0|\n",
            "|2008-11-21 00:00:00|    2600| 730000|       house|       3|   701050.0|\n",
            "+-------------------+--------+-------+------------+--------+-----------+\n",
            "only showing top 15 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Стоимость последнего проданного дома до текущего (в SQL)\n",
        "df.registerTempTable('df_task_1_3')\n",
        "\n",
        "spark.sql('''\n",
        "select *, \n",
        "LAG(price, 1, 0) OVER(ORDER BY datesold) AS prev_price\n",
        "FROM df_task_1_3\n",
        "''').show(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9PxC2FW5Bjo",
        "outputId": "5bf7c6a7-8e79-4417-b2de-4086381f9470"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
            "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------+-------+------------+--------+----------+\n",
            "|           datesold|postcode|  price|propertyType|bedrooms|prev_price|\n",
            "+-------------------+--------+-------+------------+--------+----------+\n",
            "|2007-02-07 00:00:00|    2607| 525000|       house|       4|         0|\n",
            "|2007-02-27 00:00:00|    2906| 290000|       house|       3|    525000|\n",
            "|2007-03-07 00:00:00|    2905| 328000|       house|       3|    290000|\n",
            "|2007-03-09 00:00:00|    2905| 380000|       house|       4|    328000|\n",
            "|2007-03-21 00:00:00|    2906| 310000|       house|       3|    380000|\n",
            "|2007-04-04 00:00:00|    2905| 465000|       house|       4|    310000|\n",
            "|2007-04-24 00:00:00|    2607| 399000|       house|       3|    465000|\n",
            "|2007-04-30 00:00:00|    2606|1530000|       house|       4|    399000|\n",
            "|2007-05-24 00:00:00|    2902| 359000|       house|       3|   1530000|\n",
            "|2007-05-25 00:00:00|    2906| 320000|       house|       3|    359000|\n",
            "|2007-06-26 00:00:00|    2902| 385000|       house|       3|    320000|\n",
            "|2007-06-27 00:00:00|    2906| 305000|       house|       3|    385000|\n",
            "|2007-06-27 00:00:00|    2612| 850000|       house|       4|    305000|\n",
            "|2007-06-27 00:00:00|    2606| 300000|        unit|       2|    850000|\n",
            "|2007-06-28 00:00:00|    2904| 765000|       house|       4|    300000|\n",
            "+-------------------+--------+-------+------------+--------+----------+\n",
            "only showing top 15 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Стоимость последнего проданного дома до текущего (в pyspark)\n",
        "\n",
        "w = Window().orderBy('datesold')\n",
        "df.withColumn('prev_price', F.lag('price', 1, 0).over(w)).show(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohdnV9u84Naw",
        "outputId": "9f0cd03b-c4ba-470f-c45d-cc8379334ef8"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------+-------+------------+--------+----------+\n",
            "|           datesold|postcode|  price|propertyType|bedrooms|prev_price|\n",
            "+-------------------+--------+-------+------------+--------+----------+\n",
            "|2007-02-07 00:00:00|    2607| 525000|       house|       4|         0|\n",
            "|2007-02-27 00:00:00|    2906| 290000|       house|       3|    525000|\n",
            "|2007-03-07 00:00:00|    2905| 328000|       house|       3|    290000|\n",
            "|2007-03-09 00:00:00|    2905| 380000|       house|       4|    328000|\n",
            "|2007-03-21 00:00:00|    2906| 310000|       house|       3|    380000|\n",
            "|2007-04-04 00:00:00|    2905| 465000|       house|       4|    310000|\n",
            "|2007-04-24 00:00:00|    2607| 399000|       house|       3|    465000|\n",
            "|2007-04-30 00:00:00|    2606|1530000|       house|       4|    399000|\n",
            "|2007-05-24 00:00:00|    2902| 359000|       house|       3|   1530000|\n",
            "|2007-05-25 00:00:00|    2906| 320000|       house|       3|    359000|\n",
            "|2007-06-26 00:00:00|    2902| 385000|       house|       3|    320000|\n",
            "|2007-06-27 00:00:00|    2906| 305000|       house|       3|    385000|\n",
            "|2007-06-27 00:00:00|    2612| 850000|       house|       4|    305000|\n",
            "|2007-06-27 00:00:00|    2606| 300000|        unit|       2|    850000|\n",
            "|2007-06-28 00:00:00|    2904| 765000|       house|       4|    300000|\n",
            "+-------------------+--------+-------+------------+--------+----------+\n",
            "only showing top 15 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qvh2x6_8YU3F"
      },
      "source": [
        "## Задание 2\n",
        "В итоге у вас таблица с колонками (или нечто похожее):\n",
        "*   price\n",
        "*   Среднегодовая цена\n",
        "*  Средняя стомость 10 проданных домов до текущего в том же районе (4digit postcode) (1 балл)\n",
        "*  Средняя стомость 10 проданных домов после текущего в том же районе (4digit postcode) (1 балл)\n",
        "*  Стоимость последнего проданного дома до текущего ((1 балл)\n",
        "*  и др.\n",
        "\n",
        "Посчитайте кол-во уникальных значений в каждой строчке (unique(row)) (ипользуйте udf). Попробуйте сделать то же самое используя pandas udf."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w_y = Window().orderBy('year')\n",
        "\n",
        "w_prev = Window().partitionBy('postcode')\\\n",
        "            .orderBy('datesold')\\\n",
        "            .rowsBetween(Window.currentRow - 9, Window.currentRow)\n",
        "\n",
        "w_next = Window().partitionBy('postcode')\\\n",
        "            .orderBy('datesold')\\\n",
        "            .rowsBetween(Window.currentRow, Window.currentRow + 9)\n",
        "\n",
        "w = Window().orderBy('datesold')\n",
        "\n",
        "df = df.withColumn('year', F.split(\"datesold\", \"-\").getItem(0))\\\n",
        "       .withColumn('mean', F.mean('price').over(w_y))\\\n",
        "       .withColumn('avg_10_prev', F.mean('price').over(w_prev))\\\n",
        "       .withColumn('avg_10_next', F.mean('price').over(w_next))\\\n",
        "       .withColumn('prev_price', F.lag('price', 1, 0).over(w))\n",
        "\n",
        "df.show(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYa1J9o950BP",
        "outputId": "3b43e796-c1e8-4860-e56d-24bf3c241192"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------+-------+------------+--------+----+-----------------+-----------------+-----------+----------+\n",
            "|           datesold|postcode|  price|propertyType|bedrooms|year|             mean|      avg_10_prev|avg_10_next|prev_price|\n",
            "+-------------------+--------+-------+------------+--------+----+-----------------+-----------------+-----------+----------+\n",
            "|2007-07-08 00:00:00|    2600| 327000|       house|       1|2007|522377.2108843537|         327000.0|   669050.0|    900000|\n",
            "|2007-08-16 00:00:00|    2600| 790000|       house|       4|2007|522377.2108843537|         558500.0|   708350.0|    625000|\n",
            "|2007-12-05 00:00:00|    2600| 825000|       house|       3|2007|522377.2108843537|647333.3333333334|   698350.0|    620000|\n",
            "|2008-01-21 00:00:00|    2600| 315000|        unit|       1|2008| 499156.106870229|         564250.0|   679350.0|    580000|\n",
            "|2008-04-24 00:00:00|    2600| 292500|       house|       1|2008| 499156.106870229|         509900.0|   742850.0|    445000|\n",
            "|2008-05-30 00:00:00|    2600| 329000|        unit|       2|2008| 499156.106870229|         479750.0|   786600.0|    357000|\n",
            "|2008-06-19 00:00:00|    2600| 765000|       house|       5|2008| 499156.106870229|         520500.0|   839200.0|    362000|\n",
            "|2008-07-29 00:00:00|    2600| 927000|       house|       4|2008| 499156.106870229|         571312.5|   868450.0|    365000|\n",
            "|2008-09-02 00:00:00|    2600|1380000|       house|       5|2008| 499156.106870229|661166.6666666666|   805750.0|    541000|\n",
            "|2008-09-08 00:00:00|    2600| 740000|       house|       3|2008| 499156.106870229|         669050.0|   715250.0|    360500|\n",
            "|2008-09-17 00:00:00|    2600| 720000|       house|       3|2008| 499156.106870229|         708350.0|   756250.0|    420000|\n",
            "|2008-09-22 00:00:00|    2600| 690000|       house|       4|2008| 499156.106870229|         698350.0|   741750.0|    685000|\n",
            "|2008-11-18 00:00:00|    2600| 635000|       house|       3|2008| 499156.106870229|         679350.0|   730550.0|    540000|\n",
            "|2008-11-18 00:00:00|    2600| 950000|       house|       3|2008| 499156.106870229|         742850.0|   755050.0|    635000|\n",
            "|2008-11-21 00:00:00|    2600| 730000|       house|       3|2008| 499156.106870229|         786600.0|   701050.0|    500000|\n",
            "+-------------------+--------+-------+------------+--------+----+-----------------+-----------------+-----------+----------+\n",
            "only showing top 15 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l = lambda row: '**'.join(row) # объединим все ячейки\n",
        "l_udf = F.udf(l, returnType='string')\n",
        "\n",
        "df.select(l_udf(F.array_distinct(F.array('*')))).count() # посчитаем кол-во уникальных"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AE33BDlD8x4e",
        "outputId": "c55e7240-1816-4471-9b04-758e9b0ebe01"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29580"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l = lambda row: '**'.join(row) # объединим все ячейки\n",
        "l_udf = F.pandas_udf(l, returnType='string')\n",
        "\n",
        "df.select(l_udf(F.array_distinct(F.array('*')))).count() # посчитаем кол-во уникальных"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eV6P_dNgXhI",
        "outputId": "b38d32e9-42ac-46b1-a68a-fea59bea135d"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29580"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmSZTI9PAwQb"
      },
      "source": [
        "# Задание 3\n",
        "SQL like case when или if elif else\n",
        "\n",
        "Создайте колонку, в которой в которой будет отображаться \"+\", \"-\" или \"=\", если \"Средняя стомость 10 проданных домов до текущего в том же районе\" больше, меньше или равно \"Средняя стомость 10 проданных домов после текущего в том же районе (4digit postcode)\", соотвественно.\n",
        "\n",
        "Если одно из полей Null, запишите в эту колонку \"Нет данных\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.withColumn('compare', F.when(F.col('avg_10_prev') < F.col('avg_10_next'), F.lit('+'))\\\n",
        "                          .when(F.col('avg_10_prev') > F.col('avg_10_next'), F.lit('-'))\\\n",
        "                          .otherwise('='))\\\n",
        "             .show(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rfOBthog-2Q",
        "outputId": "f5382a33-da8c-4bd9-ba28-b619c555ad8a"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------+-------+------------+--------+----+-----------------+-----------------+-----------+----------+-------+\n",
            "|           datesold|postcode|  price|propertyType|bedrooms|year|             mean|      avg_10_prev|avg_10_next|prev_price|compare|\n",
            "+-------------------+--------+-------+------------+--------+----+-----------------+-----------------+-----------+----------+-------+\n",
            "|2007-07-08 00:00:00|    2600| 327000|       house|       1|2007|522377.2108843537|         327000.0|   669050.0|    900000|      +|\n",
            "|2007-08-16 00:00:00|    2600| 790000|       house|       4|2007|522377.2108843537|         558500.0|   708350.0|    625000|      +|\n",
            "|2007-12-05 00:00:00|    2600| 825000|       house|       3|2007|522377.2108843537|647333.3333333334|   698350.0|    620000|      +|\n",
            "|2008-01-21 00:00:00|    2600| 315000|        unit|       1|2008| 499156.106870229|         564250.0|   679350.0|    580000|      +|\n",
            "|2008-04-24 00:00:00|    2600| 292500|       house|       1|2008| 499156.106870229|         509900.0|   742850.0|    445000|      +|\n",
            "|2008-05-30 00:00:00|    2600| 329000|        unit|       2|2008| 499156.106870229|         479750.0|   786600.0|    357000|      +|\n",
            "|2008-06-19 00:00:00|    2600| 765000|       house|       5|2008| 499156.106870229|         520500.0|   839200.0|    362000|      +|\n",
            "|2008-07-29 00:00:00|    2600| 927000|       house|       4|2008| 499156.106870229|         571312.5|   868450.0|    365000|      +|\n",
            "|2008-09-02 00:00:00|    2600|1380000|       house|       5|2008| 499156.106870229|661166.6666666666|   805750.0|    541000|      +|\n",
            "|2008-09-08 00:00:00|    2600| 740000|       house|       3|2008| 499156.106870229|         669050.0|   715250.0|    360500|      +|\n",
            "|2008-09-17 00:00:00|    2600| 720000|       house|       3|2008| 499156.106870229|         708350.0|   756250.0|    420000|      +|\n",
            "|2008-09-22 00:00:00|    2600| 690000|       house|       4|2008| 499156.106870229|         698350.0|   741750.0|    685000|      +|\n",
            "|2008-11-18 00:00:00|    2600| 635000|       house|       3|2008| 499156.106870229|         679350.0|   730550.0|    540000|      +|\n",
            "|2008-11-18 00:00:00|    2600| 950000|       house|       3|2008| 499156.106870229|         742850.0|   755050.0|    635000|      +|\n",
            "|2008-11-21 00:00:00|    2600| 730000|       house|       3|2008| 499156.106870229|         786600.0|   701050.0|    500000|      -|\n",
            "+-------------------+--------+-------+------------+--------+----+-----------------+-----------------+-----------+----------+-------+\n",
            "only showing top 15 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 4"
      ],
      "metadata": {
        "id": "k2q7HSEqWBVn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3pfUThFQtE6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e66ba71f-1d9b-4a5f-daff-62d6e0d3b0a7"
      },
      "source": [
        "# Создаём датасет для примеров\n",
        "dataset_1 = [\n",
        "  {\n",
        "    'key_1' : 'abc',\n",
        "    'value_1' : 10,\n",
        "    'value_2' : 20\n",
        "  },\n",
        "  {\n",
        "    'key_1' : 'def',\n",
        "    'value_1' : 100,\n",
        "    'value_2' : 300\n",
        "  }\n",
        "]\n",
        "\n",
        "dataset_2 = [\n",
        "  {\n",
        "    'key_2' : 'abc',\n",
        "    'value_1' : 5.5,\n",
        "    'value_2' : 2.2\n",
        "  },\n",
        "  {\n",
        "    'key_2' : 'xyz',\n",
        "    'value_1' : 10.1,\n",
        "    'value_2' : 13.5\n",
        "  }\n",
        "]\n",
        "\n",
        "df1 = spark.createDataFrame(dataset_1)\n",
        "print('df1')\n",
        "df1.show()\n",
        "\n",
        "df2 = spark.createDataFrame(dataset_2)\n",
        "print('df2')\n",
        "df2.show()"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df1\n",
            "+-----+-------+-------+\n",
            "|key_1|value_1|value_2|\n",
            "+-----+-------+-------+\n",
            "|  abc|     10|     20|\n",
            "|  def|    100|    300|\n",
            "+-----+-------+-------+\n",
            "\n",
            "df2\n",
            "+-----+-------+-------+\n",
            "|key_2|value_1|value_2|\n",
            "+-----+-------+-------+\n",
            "|  abc|    5.5|    2.2|\n",
            "|  xyz|   10.1|   13.5|\n",
            "+-----+-------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 4.1"
      ],
      "metadata": {
        "id": "o0E_1iKeWFeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Создайте джойн, чтобы получить следующую таблицу\n",
        "# +---+-------+-------+\n",
        "# |key|value_1|value_2|\n",
        "# +---+-------+-------+\n",
        "# |abc|     10|     20|\n",
        "# +---+-------+-------+"
      ],
      "metadata": {
        "id": "od3V0xa4V7U8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.join(df2, on=df1.key_1 == df2.key_2, how='leftsemi').show()"
      ],
      "metadata": {
        "id": "BRDcZgNKjZru",
        "outputId": "1e6eb9a7-0978-4d2e-d07b-9bcc523d9df4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+-------+\n",
            "|key_1|value_1|value_2|\n",
            "+-----+-------+-------+\n",
            "|  abc|     10|     20|\n",
            "+-----+-------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 4.2"
      ],
      "metadata": {
        "id": "qrwYa2ZAWYmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Создайте джойн, чтобы получить следующую таблицу\n",
        "# +---+-------+-------+\n",
        "# |key|value_1|value_2|\n",
        "# +---+-------+-------+\n",
        "# |def|    100|    300|\n",
        "# +---+-------+-------+"
      ],
      "metadata": {
        "id": "xEb-gGG8WQST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.join(df2, on=df1.key_1 == df2.key_2, how='leftanti').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKM1D_FIjBc9",
        "outputId": "54a79ed3-d018-4c67-b500-f081196bc792"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+-------+\n",
            "|key_1|value_1|value_2|\n",
            "+-----+-------+-------+\n",
            "|  def|    100|    300|\n",
            "+-----+-------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 4.3"
      ],
      "metadata": {
        "id": "GbzsGu30WZTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Создайте Inner джойн с условиями ---hidden---, для df1 и df2, соответсвенно\n",
        "# В  итоге получится таблица\n",
        "# +---+-------+-------+---+-------+-------+\n",
        "# |key|value_1|value_2|key|value_1|value_2|\n",
        "# +---+-------+-------+---+-------+-------+\n",
        "# |abc|     10|     20|abc|    5.5|    2.2|\n",
        "# |abc|     10|     20|xyz|   10.1|   13.5|\n",
        "# |def|    100|    300|abc|    5.5|    2.2|\n",
        "# |def|    100|    300|xyz|   10.1|   13.5|\n",
        "# +---+-------+-------+---+-------+-------+"
      ],
      "metadata": {
        "id": "XJ84QTURWWY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.join(df2, on=df1.value_2 > df2.value_2, how='inner').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zzGUJN7inrF",
        "outputId": "1532a2d8-e118-4641-b3dd-98ffac8a7fce"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+-------+-----+-------+-------+\n",
            "|key_1|value_1|value_2|key_2|value_1|value_2|\n",
            "+-----+-------+-------+-----+-------+-------+\n",
            "|  abc|     10|     20|  abc|    5.5|    2.2|\n",
            "|  abc|     10|     20|  xyz|   10.1|   13.5|\n",
            "|  def|    100|    300|  abc|    5.5|    2.2|\n",
            "|  def|    100|    300|  xyz|   10.1|   13.5|\n",
            "+-----+-------+-------+-----+-------+-------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}