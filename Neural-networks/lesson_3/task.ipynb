{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4Gr6WSWZeif"
   },
   "source": [
    "# Введение в искусственные нейронные сети\n",
    "# Урок 3. TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nvj3uNI9ZekY"
   },
   "source": [
    "## Практическое задание\n",
    "\n",
    "<ol>\n",
    "    <li> Попробуйте улучшить работу нейронной сети(разобранную на уроке) обучавшейся на датасет Fashion-MNIST.\n",
    "    <li> Опишите в комментарии к уроку - какого результата вы добились от нейросети? Что помогло вам улучшить ее точность?\n",
    "    <li> Поработайте с документацией TensorFlow 2. Попробуйте найти полезные команды TensorFlow, неразобранные на уроке\n",
    "    <li>* Попробуйте обучить нейронную сеть на TensorFlow 2 на датасете imdb_reviews.\n",
    "    </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYysdyb-CaWM"
   },
   "source": [
    "# Классификация изображений одежды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Kbg0P0Q_qbY",
    "outputId": "b25ba8f7-9ad4-4ffb-c1a6-019b136aef91"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-17 20:03:12.449675: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-17 20:03:12.499347: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-17 20:03:12.500166: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-17 20:03:13.231836: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import,division, print_function, unicode_literals\n",
    "\n",
    "#TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IjnLH5S2CaWx"
   },
   "outputs": [],
   "source": [
    "dset = keras.datasets.fashion_mnist # Импортируем Fashion MNIST датасет\n",
    "(train_images, train_labels), (test_images, test_labels) = dset.load_data()\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9ODch-OFCaW4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.3826 - accuracy: 0.8649 - 334ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3917 - accuracy: 0.8604 - 339ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3625 - accuracy: 0.8699 - 348ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3709 - accuracy: 0.8669 - 354ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3649 - accuracy: 0.8656 - 350ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3726 - accuracy: 0.8622 - 354ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3609 - accuracy: 0.8657 - 355ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3452 - accuracy: 0.8727 - 369ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3744 - accuracy: 0.8660 - 336ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3855 - accuracy: 0.8610 - 353ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3637 - accuracy: 0.8644 - 361ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3650 - accuracy: 0.8671 - 371ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3754 - accuracy: 0.8635 - 331ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.4123 - accuracy: 0.8519 - 354ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3570 - accuracy: 0.8718 - 361ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3876 - accuracy: 0.8637 - 362ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3685 - accuracy: 0.8694 - 350ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3490 - accuracy: 0.8711 - 346ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3613 - accuracy: 0.8671 - 363ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3516 - accuracy: 0.8728 - 366ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3723 - accuracy: 0.8678 - 351ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3683 - accuracy: 0.8653 - 363ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3698 - accuracy: 0.8645 - 357ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3657 - accuracy: 0.8667 - 359ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3805 - accuracy: 0.8632 - 364ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3787 - accuracy: 0.8629 - 349ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3761 - accuracy: 0.8654 - 352ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3720 - accuracy: 0.8641 - 365ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.4237 - accuracy: 0.8398 - 353ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3761 - accuracy: 0.8635 - 353ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3883 - accuracy: 0.8586 - 349ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3857 - accuracy: 0.8587 - 359ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3860 - accuracy: 0.8596 - 344ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3665 - accuracy: 0.8688 - 351ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3775 - accuracy: 0.8599 - 363ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3737 - accuracy: 0.8631 - 364ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3842 - accuracy: 0.8609 - 342ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.4019 - accuracy: 0.8504 - 352ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3778 - accuracy: 0.8661 - 354ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3821 - accuracy: 0.8623 - 360ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3881 - accuracy: 0.8613 - 357ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3849 - accuracy: 0.8641 - 349ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3747 - accuracy: 0.8661 - 355ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3823 - accuracy: 0.8620 - 375ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3716 - accuracy: 0.8670 - 356ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3729 - accuracy: 0.8705 - 353ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3898 - accuracy: 0.8613 - 359ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3780 - accuracy: 0.8662 - 365ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3844 - accuracy: 0.8564 - 351ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3673 - accuracy: 0.8686 - 356ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3882 - accuracy: 0.8606 - 350ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3701 - accuracy: 0.8688 - 360ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3892 - accuracy: 0.8567 - 354ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3806 - accuracy: 0.8626 - 353ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.4163 - accuracy: 0.8481 - 361ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3770 - accuracy: 0.8603 - 372ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.4047 - accuracy: 0.8572 - 344ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3880 - accuracy: 0.8600 - 355ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3979 - accuracy: 0.8577 - 369ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.3747 - accuracy: 0.8663 - 374ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.4782 - accuracy: 0.8348 - 364ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.4729 - accuracy: 0.8368 - 352ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.5175 - accuracy: 0.8210 - 349ms/epoch - 1ms/step\n",
      "313/313 - 0s - loss: 0.4667 - accuracy: 0.8369 - 375ms/epoch - 1ms/step\n",
      "Лучшая точность: 0.8727999925613403 при параметрах {'h1_activation': 'tanh', 'h1_size': 128, 'h2_activation': 'relu', 'h2_size': 128}\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "best_params = {}\n",
    "params = []\n",
    "for h1_activation in ['relu', 'tanh', 'sigmoid', 'linear']:\n",
    "    for h2_activation in ['relu', 'tanh', 'sigmoid', 'linear']:\n",
    "        for h1_size in [64, 128]:\n",
    "            for h2_size in [64, 128]:\n",
    "                params.append({'h1_activation': h1_activation, \n",
    "                               'h1_size': h1_size, \n",
    "                               'h2_activation': h2_activation, \n",
    "                               'h2_size': h2_size})\n",
    "                \n",
    "for param in params:\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(28, 28), name='input'),\n",
    "        keras.layers.Dense(param['h1_size'], activation=param['h1_activation'], name='hiden_one'),\n",
    "        keras.layers.Dense(param['h2_size'], activation=param['h2_activation'], name='hiden_two'),\n",
    "        keras.layers.Dense(10, name='output')\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(train_images, train_labels, epochs=3, verbose=0)\n",
    "    test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=0)\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        best_params = param\n",
    "        \n",
    "print(f'Лучшая точность: {best_acc} при параметрах {best_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Результат\n",
    "\n",
    "Лучшая точность: 0.8727999925613403 при параметрах {'h1_activation': 'tanh', 'h1_size': 128, 'h2_activation': 'relu', 'h2_size': 128}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Lhan11blCaW7"
   },
   "outputs": [],
   "source": [
    "# Т.к. задача регрессии, удобнее использовать mean square error(средне-квадратичная ошибка).\n",
    "# В качестве метрики берем mean absolute error (средний модуль ошибки)\n",
    "# model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
